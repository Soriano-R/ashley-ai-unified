{
  "categories": {
    "general": {
      "label": "General Purpose",
      "description": "Balanced conversation models suited for everyday dialogue."
    },
    "data-analytics": {
      "label": "Data & Analytics",
      "description": "Models tuned for analysis, reporting, and quantitative reasoning."
    },
    "ml-ai": {
      "label": "ML & Engineering",
      "description": "Advanced coding, automation, and machine learning research models."
    },
    "nsfw": {
      "label": "NSFW / Unfiltered",
      "description": "Explicit, uncensored relationship models."
    }
  },
  "models": {
    "qwen-2.5-7b": {
      "model_name": "Qwen/Qwen2.5-7B-Instruct",
      "display_name": "Qwen 2.5 7B Instruct",
      "max_length": 32768,
      "quantization": "pytorch",
      "format": "pytorch",
      "description": "Balanced 7B assistant with long context and strong multilingual support.",
      "categories": ["general", "data-analytics"],
      "capabilities": ["general", "analysis", "multilingual"]
    },
    "qwen-2.5-7b-gguf": {
      "model_name": "Qwen/Qwen2.5-7B-Instruct-GGUF",
      "display_name": "Qwen 2.5 7B (GGUF)",
      "max_length": 32768,
      "quantization": "gguf",
      "format": "gguf",
      "description": "Quantised Qwen 2.5 for efficient CPU inference.",
      "categories": ["general", "data-analytics"],
      "capabilities": ["general", "analysis"]
    },
    "mistral-7b": {
      "model_name": "mistralai/Mistral-7B-Instruct-v0.2",
      "display_name": "Mistral 7B Instruct",
      "max_length": 8192,
      "quantization": "pytorch",
      "format": "pytorch",
      "description": "Fast, lightweight assistant ideal for friendly dialogue. (Trainable)",
      "categories": ["general"],
      "capabilities": ["general", "creative"],
      "trainable": true
    },
    "mistral-7b-gguf": {
      "model_name": "mistralai/Mistral-7B-Instruct-v0.2-GGUF",
      "display_name": "Mistral 7B (GGUF)",
      "max_length": 8192,
      "quantization": "gguf",
      "format": "gguf",
      "description": "GGUF quantised Mistral 7B for light hardware.",
      "categories": ["general"],
      "capabilities": ["general", "creative"]
    },
    "deepseek-math-7b": {
      "model_name": "deepseek-ai/deepseek-math-7b-instruct",
      "display_name": "DeepSeek Math 7B",
      "max_length": 8192,
      "quantization": "pytorch",
      "format": "pytorch",
      "description": "Math and analytics focused assistant for quantitative problems.",
      "categories": ["data-analytics", "ml-ai"],
      "capabilities": ["analysis", "math"]
    },
    "deepseek-math-7b-gguf": {
      "model_name": "deepseek-ai/deepseek-math-7b-instruct-GGUF",
      "display_name": "DeepSeek Math 7B (GGUF)",
      "max_length": 8192,
      "quantization": "gguf",
      "format": "gguf",
      "description": "GGUF variant of DeepSeek Math for CPU deployments.",
      "categories": ["data-analytics", "ml-ai"],
      "capabilities": ["analysis", "math"]
    },
    "deepseek-coder-v2": {
      "model_name": "deepseek-ai/DeepSeek-Coder-V2-Instruct",
      "display_name": "DeepSeek Coder V2",
      "max_length": 8192,
      "quantization": "pytorch",
      "format": "pytorch",
      "description": "High-quality coding model with strong Python and automation skills.",
      "categories": ["ml-ai", "data-analytics"],
      "capabilities": ["coding", "analysis"]
    },
    "deepseek-coder-v2-gguf": {
      "model_name": "deepseek-ai/DeepSeek-Coder-V2-Instruct-GGUF",
      "display_name": "DeepSeek Coder V2 (GGUF)",
      "max_length": 8192,
      "quantization": "gguf",
      "format": "gguf",
      "description": "CPU friendly quantised DeepSeek Coder V2.",
      "categories": ["ml-ai", "data-analytics"],
      "capabilities": ["coding", "analysis"]
    },
    "code-llama-13b": {
      "model_name": "codellama/CodeLlama-13b-Instruct-hf",
      "display_name": "Code Llama 13B Instruct",
      "max_length": 16384,
      "quantization": "pytorch",
      "format": "pytorch",
      "description": "Large coding assistant optimised for Python and software design.",
      "categories": ["ml-ai"],
      "capabilities": ["coding"]
    },
    "code-llama-13b-gguf": {
      "model_name": "codellama/CodeLlama-13b-Instruct-hf-GGUF",
      "display_name": "Code Llama 13B (GGUF)",
      "max_length": 16384,
      "quantization": "gguf",
      "format": "gguf",
      "description": "GGUF quantised Code Llama 13B.",
      "categories": ["ml-ai"],
      "capabilities": ["coding"]
    },
    "code-llama-7b": {
      "model_name": "meta-llama/CodeLlama-7b-Python-hf",
      "display_name": "Code Llama 7B Python",
      "max_length": 8192,
      "quantization": "pytorch",
      "format": "pytorch",
      "description": "Lightweight Python coding helper for scripts and automation.",
      "categories": ["ml-ai"],
      "capabilities": ["coding"]
    },
    "code-llama-7b-gguf": {
      "model_name": "meta-llama/CodeLlama-7b-Python-hf-GGUF",
      "display_name": "Code Llama 7B (GGUF)",
      "max_length": 8192,
      "quantization": "gguf",
      "format": "gguf",
      "description": "GGUF quantised Code Llama 7B.",
      "categories": ["ml-ai"],
      "capabilities": ["coding"]
    },
    "undiopenhermes-7b": {
      "model_name": "Undi95/UndiOpenHermes-2.5-Mistral-7B",
      "display_name": "UndiOpenHermes 7B",
      "max_length": 8192,
      "quantization": "pytorch",
      "format": "pytorch",
      "description": "Unfiltered NSFW dialogue model.",
      "categories": ["nsfw"],
      "capabilities": ["nsfw"]
    },
    "undiopenhermes-7b-gguf": {
      "model_name": "Undi95/UndiOpenHermes-2.5-Mistral-7B-GGUF",
      "display_name": "UndiOpenHermes 7B (GGUF)",
      "max_length": 8192,
      "quantization": "gguf",
      "format": "gguf",
      "description": "GGUF NSFW model for CPU inference.",
      "categories": ["nsfw"],
      "capabilities": ["nsfw"]
    },
    "openhermes-7b-gptq": {
      "model_name": "TheBloke/OpenHermes-2.5-Mistral-7B-GPTQ",
      "display_name": "OpenHermes 7B GPTQ",
      "max_length": 8192,
      "quantization": "pytorch",
      "format": "gptq",
      "description": "GPTQ compressed NSFW assistant.",
      "categories": ["nsfw"],
      "capabilities": ["nsfw"]
    },
    "openhermes-7b-gptq-gguf": {
      "model_name": "TheBloke/OpenHermes-2.5-Mistral-7B-GPTQ-GGUF",
      "display_name": "OpenHermes 7B GPTQ (GGUF)",
      "max_length": 8192,
      "quantization": "gguf",
      "format": "gguf",
      "description": "GGUF conversion of OpenHermes GPTQ.",
      "categories": ["nsfw"],
      "capabilities": ["nsfw"]
    },
    "nous-hermes-7b-gptq": {
      "model_name": "NousResearch/Nous-Hermes-2-Mistral-7B-DPO",
      "display_name": "Nous Hermes 7B GPTQ",
      "max_length": 8192,
      "quantization": "pytorch",
      "format": "gptq",
      "description": "Candid NSFW assistant with creative flair.",
      "categories": ["nsfw"],
      "capabilities": ["nsfw"]
    },
    "nous-hermes-7b-gptq-gguf": {
      "model_name": "NousResearch/Nous-Hermes-2-Mistral-7B-DPO-GGUF",
      "display_name": "Nous Hermes 7B GPTQ (GGUF)",
      "max_length": 8192,
      "quantization": "gguf",
      "format": "gguf",
      "description": "GGUF conversion of Nous Hermes GPTQ.",
      "categories": ["nsfw"],
      "capabilities": ["nsfw"]
    },
    "chronos-hermes-13b-gptq": {
      "model_name": "TheBloke/Chronos-Hermes-13B-GPTQ",
      "display_name": "Chronos Hermes 13B GPTQ",
      "max_length": 16384,
      "quantization": "pytorch",
      "format": "gptq",
      "description": "High parameter NSFW assistant with detailed memory.",
      "categories": ["nsfw"],
      "capabilities": ["nsfw"]
    },
    "chronos-hermes-13b-gptq-gguf": {
      "model_name": "TheBloke/Chronos-Hermes-13B-GPTQ-GGUF",
      "display_name": "Chronos Hermes 13B GPTQ (GGUF)",
      "max_length": 16384,
      "quantization": "gguf",
      "format": "gguf",
      "description": "GGUF conversion of Chronos Hermes 13B.",
      "categories": ["nsfw"],
      "capabilities": ["nsfw"]
    },
    "undiplatypus2-13b-gptq": {
      "model_name": "TheBloke/UndiPlatypus2-13B-GPTQ",
      "display_name": "UndiPlatypus 13B GPTQ",
      "max_length": 16384,
      "quantization": "pytorch",
      "format": "gptq",
      "description": "Playful NSFW assistant with long-form memory.",
      "categories": ["nsfw"],
      "capabilities": ["nsfw"]
    },
    "undiplatypus2-13b-gptq-gguf": {
      "model_name": "TheBloke/UndiPlatypus2-13B-GPTQ-GGUF",
      "display_name": "UndiPlatypus 13B GPTQ (GGUF)",
      "max_length": 16384,
      "quantization": "gguf",
      "format": "gguf",
      "description": "GGUF conversion of UndiPlatypus 13B.",
      "categories": ["nsfw"],
      "capabilities": ["nsfw"]
    },
    "openorca-platypus2-13b-gptq": {
      "model_name": "TheBloke/OpenOrca-Platypus2-13B-GPTQ",
      "display_name": "OpenOrca Platypus2 13B GPTQ",
      "max_length": 16384,
      "quantization": "pytorch",
      "format": "gptq",
      "description": "NSFW model with blend of Platypus and OpenOrca alignment.",
      "categories": ["nsfw"],
      "capabilities": ["nsfw"]
    },
    "openorca-platypus2-13b-gptq-gguf": {
      "model_name": "TheBloke/OpenOrca-Platypus2-13B-GPTQ-GGUF",
      "display_name": "OpenOrca Platypus2 13B (GGUF)",
      "max_length": 16384,
      "quantization": "gguf",
      "format": "gguf",
      "description": "GGUF conversion of OpenOrca Platypus2.",
      "categories": ["nsfw"],
      "capabilities": ["nsfw"]
    },
    "openai": {
      "model_name": "gpt-4o-mini",
      "display_name": "OpenAI GPT-4o Mini",
      "max_length": 4096,
      "quantization": "api",
      "format": "api",
      "description": "Cloud fallback model via OpenAI API.",
      "categories": ["general"],
      "capabilities": ["general"],
      "trainable": false
    },
    "openrouter-mistral-7b-free": {
      "model_name": "mistralai/mistral-7b-instruct:free",
      "display_name": "Mistral 7B Instruct (Free)",
      "max_length": 8192,
      "quantization": "api",
      "format": "openrouter",
      "description": "Fast 7B parameter model optimized for instruction following. Free tier via OpenRouter.",
      "categories": ["general"],
      "capabilities": ["general", "creative"],
      "trainable": false
    },
    "openrouter-phi-3-free": {
      "model_name": "microsoft/phi-3-mini-128k-instruct:free",
      "display_name": "Phi-3 Mini (Free)",
      "max_length": 128000,
      "quantization": "api",
      "format": "openrouter",
      "description": "Microsoft's compact but powerful model with massive 128K context window. Free tier.",
      "categories": ["general", "data-analytics"],
      "capabilities": ["general", "analysis", "coding"],
      "trainable": false
    },
    "openrouter-gemma-7b-free": {
      "model_name": "google/gemma-7b-it:free",
      "display_name": "Gemma 7B IT (Free)",
      "max_length": 8192,
      "quantization": "api",
      "format": "openrouter",
      "description": "Google's open-source instruction-tuned model. Free tier via OpenRouter.",
      "categories": ["general"],
      "capabilities": ["general", "creative"],
      "trainable": false
    },
    "openrouter-qwen-7b-free": {
      "model_name": "qwen/qwen-2-7b-instruct:free",
      "display_name": "Qwen 2 7B Instruct (Free)",
      "max_length": 32768,
      "quantization": "api",
      "format": "openrouter",
      "description": "Alibaba's multilingual model with strong performance. Free tier.",
      "categories": ["general", "data-analytics"],
      "capabilities": ["general", "multilingual", "analysis"],
      "trainable": false
    },
    "openrouter-llama-3-8b-free": {
      "model_name": "meta-llama/llama-3-8b-instruct:free",
      "display_name": "Llama 3 8B Instruct (Free)",
      "max_length": 8192,
      "quantization": "api",
      "format": "openrouter",
      "description": "Meta's open-source model with strong general capabilities. Free tier.",
      "categories": ["general"],
      "capabilities": ["general", "creative", "coding"],
      "trainable": false
    },
    "openrouter-gemini-image-free": {
      "model_name": "google/gemini-2.5-flash-image-preview:free",
      "display_name": "Gemini 2.5 Flash Image (Free)",
      "max_length": 8192,
      "quantization": "api",
      "format": "openrouter-image",
      "description": "Google's image generation model with contextual understanding. Generates 1024x1024 images. Free tier.",
      "categories": ["general"],
      "capabilities": ["image-generation", "creative"],
      "trainable": false,
      "modalities": ["image", "text"]
    }
  },
  "default_model": "mistral-7b",
  "inference_config": {
    "max_new_tokens": 64,
    "temperature": 0.7,
    "top_p": 0.9,
    "do_sample": true,
    "pad_token_id": null
  }
}
